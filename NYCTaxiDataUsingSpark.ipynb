{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Engineer Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Raw Trip Data:\n",
    "    \n",
    "medallion,hack_license,vendor_id,rate_code,store_and_fwd_flag,pickup_datetime,dropoff_datetime,passenger_count,trip_time_in_secs,trip_distance,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude\n",
    "89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,1,N,2013-01-01 15:11:48,2013-01-01 15:18:10,4,382,1.00,-73.978165,40.757977,-73.989838,40.751171\n",
    "0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-06 00:18:35,2013-01-06 00:22:54,1,259,1.50,-74.006683,40.731781,-73.994499,40.75066\n",
    "0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-05 18:49:41,2013-01-05 18:54:23,1,282,1.10,-74.004707,40.73777,-74.009834,40.726002\n",
    "DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:54:15,2013-01-07 23:58:20,2,244,.70,-73.974602,40.759945,-73.984734,40.759388\n",
    "DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:25:03,2013-01-07 23:34:24,1,560,2.10,-73.97625,40.748528,-74.002586,40.747868\n",
    "20D9ECB2CA0767CF7A01564DF2844A3E,598CCE5B9C1918568DEE71F43CF26CD2,CMT,1,N,2013-01-07 15:27:48,2013-01-07 15:38:37,1,648,1.70,-73.966743,40.764252,-73.983322,40.743763\n",
    "496644932DF3932605C22C7926FF0FE0,513189AD756FF14FE670D10B92FAF04C,CMT,1,N,2013-01-08 11:01:15,2013-01-08 11:08:14,1,418,.80,-73.995804,40.743977,-74.007416,40.744343\n",
    "0B57B9633A2FECD3D3B1944AFC7471CF,CCD4367B417ED6634D986F573A552A62,CMT,1,N,2013-01-07 12:39:18,2013-01-07 13:10:56,3,1898,10.70,-73.989937,40.756775,-73.86525,40.77063\n",
    "2C0E91FF20A856C891483ED63589F982,1DA2F6543A62B8ED934771661A9D2FA0,CMT,1,N,2013-01-07 18:15:47,2013-01-07 18:20:47,1,299,.80,-73.980072,40.743137,-73.982712,40.735336\n",
    "2D4B95E2FA7B2E85118EC5CA4570FA58,CD2F522EEE1FF5F5A8D8B679E23576B3,CMT,1,N,2013-01-07 15:33:28,2013-01-07 15:49:26,2,957,2.50,-73.977936,40.786983,-73.952919,40.80637\n",
    "E12F6AF991172EAC3553144A0AF75A19,06918214E951FA0003D1CC54955C2AB0,CMT,1,N,2013-01-08 13:11:52,2013-01-08 13:19:50,1,477,1.30,-73.982452,40.773167,-73.964134,40.773815\n",
    "E12F6AF991172EAC3553144A0AF75A19,06918214E951FA0003D1CC54955C2AB0,CMT,1,N,2013-01-08 09:50:05,2013-01-08 10:02:54,1,768,.70,-73.99556,40.749294,-73.988686,40.759052\n",
    "78FFD9CD0CDA541F335EF8B38FB494D6,E949C583ECF62C8F03FDCE1484954A08,CMT,1,N,2013-01-10 12:07:08,2013-01-10 12:17:29,1,620,2.30,-73.971497,40.791321,-73.964478,40.775921\n",
    "237F49C3ECC11F5024B254268F054384,93C363DDF8ED9385D65FAD07CE3F5F07,CMT,1,N,2013-01-07 07:35:47,2013-01-07 07:46:00,1,612,2.30,-73.98851,40.774307,-73.981094,40.755325\n",
    "\n",
    "### Sample Raw Trip Fare Data:\n",
    "medallion,hack_license,vendor_id,pickup_datetime,payment_type,fare_amount,surcharge,mta_tax,tip_amount,tolls_amount,total_amount\n",
    "89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,2013-01-01 15:11:48,CSH,6.5,0,0.5,0,0,7\n",
    "0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-06 00:18:35,CSH,6,0.5,0.5,0,0,7\n",
    "0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-05 18:49:41,CSH,5.5,1,0.5,0,0,7\n",
    "DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:54:15,CSH,5,0.5,0.5,0,0,6\n",
    "DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:25:03,CSH,9.5,0.5,0.5,0,0,10.5\n",
    "20D9ECB2CA0767CF7A01564DF2844A3E,598CCE5B9C1918568DEE71F43CF26CD2,CMT,2013-01-07 15:27:48,CSH,9.5,0,0.5,0,0,10\n",
    "496644932DF3932605C22C7926FF0FE0,513189AD756FF14FE670D10B92FAF04C,CMT,2013-01-08 11:01:15,CSH,6,0,0.5,0,0,6.5\n",
    "0B57B9633A2FECD3D3B1944AFC7471CF,CCD4367B417ED6634D986F573A552A62,CMT,2013-01-07 12:39:18,CSH,34,0,0.5,0,4.8,39.3\n",
    "2C0E91FF20A856C891483ED63589F982,1DA2F6543A62B8ED934771661A9D2FA0,CMT,2013-01-07 18:15:47,CSH,5.5,1,0.5,0,0,7\n",
    "2D4B95E2FA7B2E85118EC5CA4570FA58,CD2F522EEE1FF5F5A8D8B679E23576B3,CMT,2013-01-07 15:33:28,CSH,13,0,0.5,0,0,13.5\n",
    "E12F6AF991172EAC3553144A0AF75A19,06918214E951FA0003D1CC54955C2AB0,CMT,2013-01-08 13:11:52,CSH,7.5,0,0.5,0,0,8\n",
    "E12F6AF991172EAC3553144A0AF75A19,06918214E951FA0003D1CC54955C2AB0,CMT,2013-01-08 09:50:05,CSH,9,0,0.5,0,0,9.5\n",
    "78FFD9CD0CDA541F335EF8B38FB494D6,E949C583ECF62C8F03FDCE1484954A08,CMT,2013-01-10 12:07:08,CSH,9.5,0,0.5,0,0,10\n",
    "237F49C3ECC11F5024B254268F054384,93C363DDF8ED9385D65FAD07CE3F5F07,CMT,2013-01-07 07:35:47,CSH,10,0,0.5,0,0,10.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes of Steps\n",
    "\n",
    "## Data Sanitization\n",
    "\n",
    "1. Trip_fare data has problem with headers - there were extra spaces that was causing trouble while reading the dataset and selecting columns. So, just trimmed those spaces to cleanse the data.\n",
    "2. Loaded the Jan month - week 2 data for both Trip_data and Trip Fare datasets\n",
    "3. Both the datasets have 3265929 rows for week 2 of jan month that confirms that every ride has information in both datasets on a high level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan\n",
      "East 43rd Street\n"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"NYCTaxiLocationFinder\")\n",
    "startlocation = geolocator.reverse(\"40.75,-73.97\")\n",
    "# print(startlocation.address)\n",
    "# print(startlocation.raw)\n",
    "# print(startlocation.raw['address']['suburb'])\n",
    "# print(startlocation.raw['address']['road'])\n",
    "endlocation = geolocator.reverse(\"40.75, -73.98\")\n",
    "# print(endlocation.raw)\n",
    "# print(endlocation.address)\n",
    "# print(endlocation.raw['address']['suburb'])\n",
    "# print(endlocation.raw['address']['road'])\n",
    "\n",
    "def getSuburb(latLongval):\n",
    "    location = geolocator.reverse(latLongval)\n",
    "    return location.raw['address']['suburb']\n",
    "\n",
    "def getLocation(latLongval):\n",
    "    location = geolocator.reverse(latLongval)\n",
    "    return (location.raw['address']['suburb'], location.raw['address']['road'])\n",
    "\n",
    "suburb, road = getLocation(\"40.75,-73.97\")\n",
    "print(suburb)\n",
    "print(road)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "from pyspark import SparkContext as sc\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# SparkSession and Log4j initialization\n",
    "spark = SparkSession.builder.appName(\"ElulaDataLake\").getOrCreate()\n",
    "log4jLogger = spark._jvm.org.apache.log4j\n",
    "log = log4jLogger.LogManager.getLogger(__name__)\n",
    "\n",
    "# To Register UDF to get the suburb location. But currenty reverse Geo coding is timing out.\n",
    "spark.udf.register(\"getSuburb\", getSuburb)\n",
    "\n",
    "class NYCTaxiDataPipeline:\n",
    "    \n",
    "    weekdays=(\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\")\n",
    "    \n",
    "    # Load Trip Data\n",
    "    def loadTripData(self,filePath,format = \"csv\"):\n",
    "        log.info(f\"loading Trip data from ${filePath}\")\n",
    "        tripInfoDB = spark.read.format(format).options(header=\"true\", inferSchema=\"true\").load(filePath)\n",
    "        log.info(f\"Finished loading Trip Info from ${filePath}\")\n",
    "        return tripInfoDB\n",
    "\n",
    "    def loadTripFareData(self,filePath, format = \"csv\"):\n",
    "        log.info(f\"loading Trip Fare data from ${filePath}\")\n",
    "        tripFareData = spark.read.format(format).options(header=\"true\", inferSchema=\"true\").load(filePath)\n",
    "        log.info(f\"Finished loading Trip Fare Info from ${filePath}\")\n",
    "        return tripFareData\n",
    "    \n",
    "    def initiatePipeline(self,tripDataPath,tripFarePath,outputFilePath,tripDataFormat=\"csv\",tripFareFormat=\"csv\",outputFileFormat=\"csv\"):\n",
    "        tripData = loadTripData(tripDataPath, tripDataFormat)\n",
    "        tripData.createOrReplaceTempView(\"trip_data\")\n",
    "        janTripDataWeek2=spark.sql(\"select medallion,hack_license,vendor_id,pickup_datetime,dayofweek(pickup_datetime) as pickupday,weekofyear(pickup_datetime) as pickupweek,dropoff_datetime,passenger_count,trip_time_in_secs,trip_distance,pickup_longitude,pickup_latitude,concat(pickup_latitude,',',pickup_longitude) as pickup_lat_long,dropoff_longitude,dropoff_latitude,concat(dropoff_latitude,',',dropoff_longitude) as dropoff_lat_long from trip_data where weekofyear(pickup_datetime) == 2\")\n",
    "        week2TripData = janTripDataWeek2.createOrReplaceTempView(\"trip_data_week_2\")\n",
    "        \n",
    "        tripFare = loadTripFareData(tripFarePath, tripFareFormat)\n",
    "        tripFare.createOrReplaceTempView(\"trip_fare\")\n",
    "        janTripFareWeek2 = spark.sql(\"select medallion,hack_license,vendor_id,pickup_datetime,payment_type,fare_amount,surcharge,mta_tax,tip_amount,tolls_amount,total_amount from trip_fare where weekofyear(pickup_datetime) == 2\")\n",
    "        week2TripFare = janTripFareWeek2.createOrReplaceTempView(\"trip_fare_week_2\")\n",
    "        tripInfoWeek2Cons = spark.sql(\"select data.medallion,data.hack_license,data.vendor_id,data.pickup_datetime,data.pickupday,data.pickupweek,data.dropoff_datetime,data.passenger_count,data.trip_time_in_secs,data.trip_distance,data.pickup_latitude,data.pickup_longitude,data.dropoff_latitude,data.dropoff_longitude, fare.payment_type, fare.fare_amount,fare.surcharge,fare.mta_tax,fare.tip_amount,fare.tolls_amount,fare.total_amount from trip_data_week_2 as data inner join trip_fare_week_2 as fare on data.medallion = fare.medallion and data.hack_license == fare.hack_license and data.vendor_id = fare.vendor_id and data.pickup_datetime = fare.pickup_datetime\")\n",
    "\n",
    "        tripInfoWeek2Cons.coalesce(1).write.format(outputFileFormat).option(\"header\", True).save(outputFilePath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripDataPath=\"/Users/karthikdivya/Desktop/JobRelated/Companies/Elula/trip_data/trip_data_1.csv\"\n",
    "tripFarePath=\"/Users/karthikdivya/Desktop/JobRelated/Companies/Elula/trip_fare/trip_fare_1.csv\"\n",
    "outputFilePath=\"/Users/karthikdivya/Desktop/JobRelated/Companies/Elula/output_consolidated_final/\"\n",
    "NYCTaxiDataPipeline().initiatePipeline(tripDataPath,tripFarePath,outputFilePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions to answer from data\n",
    "\n",
    "1. Which location/suburb has most number of passengers ?\n",
    "2. Which day of the week accounts for maximum revenue ?\n",
    "3. Which location contributes to the maximum revenue ?\n",
    "4. Which payment type is leastly preferred by passengers ?\n",
    "5. Which payment types are mostly preferred by passengers ?\n",
    "6. What is the maximum trip distance travelled ? from which location to which location and the charge ?\n",
    "7. What is the least distance travelled ?\n",
    "\n",
    "### Things to Do\n",
    "\n",
    "1. Reliable and stable reverse geocoder service to convert the lat & long info to suburbs for grouping.\n",
    "2. Process atleast last 6 months or 1 year worth of data at once and plot time series to capture seasonal trends.\n",
    "3. Growth in terms of number of passengers over the years and the number of vehicles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
